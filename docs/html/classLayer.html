<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>My Project: Layer Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">My Project
   &#160;<span id="projectnumber">0.5</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="classLayer-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">Layer Class Reference</div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:ac7b74e6fa9a90f78753c0318cf731719"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classLayer.html#ac7b74e6fa9a90f78753c0318cf731719">Layer</a> (size_t <a class="el" href="classLayer.html#a5f699c67410ebc5acad98cc5d3a9b5ec">lenIn</a>, size_t <a class="el" href="classLayer.html#a57aa9a6491ea690f338f145c62a582f2">lenOut</a>, <a class="el" href="classAFActivationFunction.html">AFActivationFunction</a>&lt; double &gt; *<a class="el" href="classLayer.html#abe40a67ce33b17440ff6b0571b0c49e5">activationFunction</a>)</td></tr>
<tr class="separator:ac7b74e6fa9a90f78753c0318cf731719"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab725324396c041488c108238e0c23037"><td class="memItemLeft" align="right" valign="top"><a id="ab725324396c041488c108238e0c23037"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>randomizeWeights</b> ()</td></tr>
<tr class="separator:ab725324396c041488c108238e0c23037"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad8fbfc2d20832ea5f8174074f26aaba1"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classLayer.html#ad8fbfc2d20832ea5f8174074f26aaba1">forwardPass</a> (vector&lt; double &gt; *<a class="el" href="classLayer.html#ab72e6e0db19cd376c3c62b59e5f55e56">inputVals</a>, vector&lt; double &gt; *<a class="el" href="classLayer.html#a42731a44d761c086b0c4914fcc2ba8a0">outputVals</a>)</td></tr>
<tr class="separator:ad8fbfc2d20832ea5f8174074f26aaba1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac447454d60f91693dc98020f0063da5a"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classLayer.html#ac447454d60f91693dc98020f0063da5a">forwardPass</a> (vector&lt; double &gt; *<a class="el" href="classLayer.html#ab72e6e0db19cd376c3c62b59e5f55e56">inputVals</a>)</td></tr>
<tr class="separator:ac447454d60f91693dc98020f0063da5a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5fa93a13d02fe9ee536d87b4980c8862"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classLayer.html#a5fa93a13d02fe9ee536d87b4980c8862">backpropagate</a> (vector&lt; double &gt; *nextDeltas, <a class="el" href="classAFMatrix.html">AFMatrix</a>&lt; double &gt; *nextWeights, vector&lt; double &gt; *newDeltas)</td></tr>
<tr class="separator:a5fa93a13d02fe9ee536d87b4980c8862"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab971a401b617ae20c5ab19310be25a70"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classLayer.html#ab971a401b617ae20c5ab19310be25a70">backpropagate</a> (vector&lt; double &gt; *nextDeltas, <a class="el" href="classAFMatrix.html">AFMatrix</a>&lt; double &gt; *nextWeights)</td></tr>
<tr class="separator:ab971a401b617ae20c5ab19310be25a70"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a662f96aaa0e56564046baf34d4afddf5"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classLayer.html#a662f96aaa0e56564046baf34d4afddf5">backpropagateBase</a> (vector&lt; double &gt; *actualVals, vector&lt; double &gt; *expectedVals, <a class="el" href="classAFLossFunction.html">AFLossFunction</a>&lt; double &gt; *lossFn, vector&lt; double &gt; *newDeltas)</td></tr>
<tr class="separator:a662f96aaa0e56564046baf34d4afddf5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af2181f3eda8a8c6898d47fc3c280313b"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classLayer.html#af2181f3eda8a8c6898d47fc3c280313b">backpropagateBase</a> (vector&lt; double &gt; *actualVals, vector&lt; double &gt; *expectedVals, <a class="el" href="classAFLossFunction.html">AFLossFunction</a>&lt; double &gt; *lossFn)</td></tr>
<tr class="separator:af2181f3eda8a8c6898d47fc3c280313b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6896bb337eee9d535030fe115e4951ef"><td class="memItemLeft" align="right" valign="top"><a id="a6896bb337eee9d535030fe115e4951ef"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>updateWeightGradient</b> ()</td></tr>
<tr class="separator:a6896bb337eee9d535030fe115e4951ef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9617331c069ebe2a8f20fd72aa017717"><td class="memItemLeft" align="right" valign="top"><a id="a9617331c069ebe2a8f20fd72aa017717"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>updateWeights</b> (double learningRate)</td></tr>
<tr class="separator:a9617331c069ebe2a8f20fd72aa017717"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:a5f699c67410ebc5acad98cc5d3a9b5ec"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classLayer.html#a5f699c67410ebc5acad98cc5d3a9b5ec">lenIn</a></td></tr>
<tr class="memdesc:a5f699c67410ebc5acad98cc5d3a9b5ec"><td class="mdescLeft">&#160;</td><td class="mdescRight">The size of the vector that this layer takes as input.  <a href="#a5f699c67410ebc5acad98cc5d3a9b5ec">More...</a><br /></td></tr>
<tr class="separator:a5f699c67410ebc5acad98cc5d3a9b5ec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a57aa9a6491ea690f338f145c62a582f2"><td class="memItemLeft" align="right" valign="top"><a id="a57aa9a6491ea690f338f145c62a582f2"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classLayer.html#a57aa9a6491ea690f338f145c62a582f2">lenOut</a></td></tr>
<tr class="memdesc:a57aa9a6491ea690f338f145c62a582f2"><td class="mdescLeft">&#160;</td><td class="mdescRight">The size of the vector that this layer outputs. <br /></td></tr>
<tr class="separator:a57aa9a6491ea690f338f145c62a582f2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab72e6e0db19cd376c3c62b59e5f55e56"><td class="memItemLeft" align="right" valign="top"><a id="ab72e6e0db19cd376c3c62b59e5f55e56"></a>
vector&lt; double &gt; *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classLayer.html#ab72e6e0db19cd376c3c62b59e5f55e56">inputVals</a></td></tr>
<tr class="memdesc:ab72e6e0db19cd376c3c62b59e5f55e56"><td class="mdescLeft">&#160;</td><td class="mdescRight">The values that this layer receives from the previous layer LEN_IN. <br /></td></tr>
<tr class="separator:ab72e6e0db19cd376c3c62b59e5f55e56"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a615b17469874e0f1d9a63236568c1be4"><td class="memItemLeft" align="right" valign="top"><a id="a615b17469874e0f1d9a63236568c1be4"></a>
vector&lt; double &gt; *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classLayer.html#a615b17469874e0f1d9a63236568c1be4">sums</a></td></tr>
<tr class="memdesc:a615b17469874e0f1d9a63236568c1be4"><td class="mdescLeft">&#160;</td><td class="mdescRight">The sums after the weights are multiplied by input value`. LEN_OUT. <br /></td></tr>
<tr class="separator:a615b17469874e0f1d9a63236568c1be4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6ba44600aedf6e90536cd76dc94562c0"><td class="memItemLeft" align="right" valign="top"><a id="a6ba44600aedf6e90536cd76dc94562c0"></a>
vector&lt; double &gt; *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classLayer.html#a6ba44600aedf6e90536cd76dc94562c0">deltas</a></td></tr>
<tr class="memdesc:a6ba44600aedf6e90536cd76dc94562c0"><td class="mdescLeft">&#160;</td><td class="mdescRight">The intermediate gradients of the loss, <code>deltas[i] = d(Error)/d(sum_i)</code> LEN_OUT. <br /></td></tr>
<tr class="separator:a6ba44600aedf6e90536cd76dc94562c0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a42731a44d761c086b0c4914fcc2ba8a0"><td class="memItemLeft" align="right" valign="top"><a id="a42731a44d761c086b0c4914fcc2ba8a0"></a>
vector&lt; double &gt; *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classLayer.html#a42731a44d761c086b0c4914fcc2ba8a0">outputVals</a></td></tr>
<tr class="memdesc:a42731a44d761c086b0c4914fcc2ba8a0"><td class="mdescLeft">&#160;</td><td class="mdescRight">The values after the sums are put through the activation function. LEN_OUT. <br /></td></tr>
<tr class="separator:a42731a44d761c086b0c4914fcc2ba8a0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acb311104d54fd7c09ea4c07006f8fc45"><td class="memItemLeft" align="right" valign="top"><a id="acb311104d54fd7c09ea4c07006f8fc45"></a>
<a class="el" href="classAFMatrix.html">AFMatrix</a>&lt; double &gt; *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classLayer.html#acb311104d54fd7c09ea4c07006f8fc45">weights</a></td></tr>
<tr class="memdesc:acb311104d54fd7c09ea4c07006f8fc45"><td class="mdescLeft">&#160;</td><td class="mdescRight">The weights which are multiplied against the input values. This has <code>lenOut</code> rows and <code>lenIn</code> cols. <br /></td></tr>
<tr class="separator:acb311104d54fd7c09ea4c07006f8fc45"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8b36a2bc8a623ab02c0545097ebc967f"><td class="memItemLeft" align="right" valign="top"><a id="a8b36a2bc8a623ab02c0545097ebc967f"></a>
<a class="el" href="classAFMatrix.html">AFMatrix</a>&lt; double &gt; *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classLayer.html#a8b36a2bc8a623ab02c0545097ebc967f">weightGradient</a></td></tr>
<tr class="memdesc:a8b36a2bc8a623ab02c0545097ebc967f"><td class="mdescLeft">&#160;</td><td class="mdescRight">The weight gradients. <code>weightGradient[i,j] = d(Error)/d(weights[i,j])</code>. Same shape as <code>weights</code>. <br /></td></tr>
<tr class="separator:a8b36a2bc8a623ab02c0545097ebc967f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abe40a67ce33b17440ff6b0571b0c49e5"><td class="memItemLeft" align="right" valign="top"><a id="abe40a67ce33b17440ff6b0571b0c49e5"></a>
<a class="el" href="classAFActivationFunction.html">AFActivationFunction</a>&lt; double &gt; *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classLayer.html#abe40a67ce33b17440ff6b0571b0c49e5">activationFunction</a></td></tr>
<tr class="memdesc:abe40a67ce33b17440ff6b0571b0c49e5"><td class="mdescLeft">&#160;</td><td class="mdescRight">The activation function <code>g</code> such that `outputValues = g(weights * InputVals). Note that g takes a vector. <br /></td></tr>
<tr class="separator:abe40a67ce33b17440ff6b0571b0c49e5"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="ac7b74e6fa9a90f78753c0318cf731719"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac7b74e6fa9a90f78753c0318cf731719">&#9670;&nbsp;</a></span>Layer()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">Layer::Layer </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>lenIn</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>lenOut</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classAFActivationFunction.html">AFActivationFunction</a>&lt; double &gt; *&#160;</td>
          <td class="paramname"><em>activationFunction</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">lenIn</td><td>The input length of this layer </td></tr>
    <tr><td class="paramname">lenOut</td><td>The output size of this layer </td></tr>
    <tr><td class="paramname">activationFn</td><td>Pass an <a class="el" href="classAFActivationFunction.html">AFActivationFunction</a> by value so this layer knows how to calculate output values. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a5fa93a13d02fe9ee536d87b4980c8862"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5fa93a13d02fe9ee536d87b4980c8862">&#9670;&nbsp;</a></span>backpropagate() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void Layer::backpropagate </td>
          <td>(</td>
          <td class="paramtype">vector&lt; double &gt; *&#160;</td>
          <td class="paramname"><em>nextDeltas</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classAFMatrix.html">AFMatrix</a>&lt; double &gt; *&#160;</td>
          <td class="paramname"><em>nextWeights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vector&lt; double &gt; *&#160;</td>
          <td class="paramname"><em>newDeltas</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Performs backpropogation algorithm. Writes this layer's new d(Err)/d(Sums) into <code>newDeltas</code>. </p><dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">LEN_OUT_NEXT</td><td>The next layer's output length </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">nextDeltas</td><td>The next layer's d(Err)/d(sums); </td></tr>
    <tr><td class="paramname">nextWeights</td><td></td></tr>
    <tr><td class="paramname">newDeltas</td><td></td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ab971a401b617ae20c5ab19310be25a70"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab971a401b617ae20c5ab19310be25a70">&#9670;&nbsp;</a></span>backpropagate() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void Layer::backpropagate </td>
          <td>(</td>
          <td class="paramtype">vector&lt; double &gt; *&#160;</td>
          <td class="paramname"><em>nextDeltas</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classAFMatrix.html">AFMatrix</a>&lt; double &gt; *&#160;</td>
          <td class="paramname"><em>nextWeights</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Performs backpropogation algorithm and writes output to <code>this-&gt;deltas</code>. </p><dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">LEN_OUT_NEXT</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">nextDeltas</td><td></td></tr>
    <tr><td class="paramname">nextWeights</td><td></td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a662f96aaa0e56564046baf34d4afddf5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a662f96aaa0e56564046baf34d4afddf5">&#9670;&nbsp;</a></span>backpropagateBase() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void Layer::backpropagateBase </td>
          <td>(</td>
          <td class="paramtype">vector&lt; double &gt; *&#160;</td>
          <td class="paramname"><em>actualVals</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vector&lt; double &gt; *&#160;</td>
          <td class="paramname"><em>expectedVals</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classAFLossFunction.html">AFLossFunction</a>&lt; double &gt; *&#160;</td>
          <td class="paramname"><em>lossFn</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vector&lt; double &gt; *&#160;</td>
          <td class="paramname"><em>newDeltas</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>The backprop algorithm for the last layer. First calculates <code>d(Err)/d(outputVals)</code>, which is the derivative of the loss function w.r.t to <code>actualVals</code>. It then calculates d(Err)/d(sums)`.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">actualVals</td><td></td></tr>
    <tr><td class="paramname">expectedVals</td><td></td></tr>
    <tr><td class="paramname">newDeltas</td><td></td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="af2181f3eda8a8c6898d47fc3c280313b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af2181f3eda8a8c6898d47fc3c280313b">&#9670;&nbsp;</a></span>backpropagateBase() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void Layer::backpropagateBase </td>
          <td>(</td>
          <td class="paramtype">vector&lt; double &gt; *&#160;</td>
          <td class="paramname"><em>actualVals</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vector&lt; double &gt; *&#160;</td>
          <td class="paramname"><em>expectedVals</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classAFLossFunction.html">AFLossFunction</a>&lt; double &gt; *&#160;</td>
          <td class="paramname"><em>lossFn</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>The backprop algorithm for the last layer. First calculates <code>d(Err)/d(outputVals)</code>, which is the derivative of the loss function w.r.t to <code>actualVals</code>. It then calculates d(Err)/d(sums)`.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">actualVals</td><td></td></tr>
    <tr><td class="paramname">expectedVals</td><td></td></tr>
    <tr><td class="paramname">newDeltas</td><td></td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ad8fbfc2d20832ea5f8174074f26aaba1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad8fbfc2d20832ea5f8174074f26aaba1">&#9670;&nbsp;</a></span>forwardPass() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void Layer::forwardPass </td>
          <td>(</td>
          <td class="paramtype">vector&lt; double &gt; *&#160;</td>
          <td class="paramname"><em>inputVals</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vector&lt; double &gt; *&#160;</td>
          <td class="paramname"><em>outputVals</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Will perform the forward pass on this <a class="el" href="classLayer.html">Layer</a>. Will take in <code>inputVals</code>, calculate weighted sums, and then pass that result to this layer's activation function. The output will be written to <code>outputVals</code>. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inputVals</td><td></td></tr>
    <tr><td class="paramname">outputVals</td><td>- outputVals[i] = this-&gt;weights.row(i).innerProduct(inputVals). </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ac447454d60f91693dc98020f0063da5a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac447454d60f91693dc98020f0063da5a">&#9670;&nbsp;</a></span>forwardPass() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void Layer::forwardPass </td>
          <td>(</td>
          <td class="paramtype">vector&lt; double &gt; *&#160;</td>
          <td class="paramname"><em>inputVals</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Will perform the forward pass on this <a class="el" href="classLayer.html">Layer</a>. Will take in <code>inputVals</code>, calculate weighted sums, and then pass that result to this layer's activation function. The output will be written to <code>outputVals</code>. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inputVals</td><td></td></tr>
    <tr><td class="paramname">outputVals</td><td>- outputVals[i] = this-&gt;weights.row(i).innerProduct(inputVals). </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="a5f699c67410ebc5acad98cc5d3a9b5ec"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5f699c67410ebc5acad98cc5d3a9b5ec">&#9670;&nbsp;</a></span>lenIn</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int Layer::lenIn</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The size of the vector that this layer takes as input. </p>
<p>Hello! </p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>src/<a class="el" href="Layer_8h_source.html">Layer.h</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
